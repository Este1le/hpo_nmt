<h1>Data &amp; Starting Kit</h1>
<p>Please get the starting kit from <a href="https://github.com/Este1le/hpo_nmt/tree/master/automl2022">github</a>. The data for 6 public Machine Translation (MT) datasets and their Transformer hyperparameter tables are in the same repo. On codalab, we will be testing on the so-en, sw-en datasets, in additional to a blind set in evaluation phase.</p>
<p>This challenge uses data from the following work:</p>
<p>Xuan Zhang and Kevin Duh, <a href="https://www.mitpressjournals.org/doi/full/10.1162/tacl_a_00322">Reproducible and Efficient Benchmarks for Hyperparameter Optimization of Neural Machine Translation Systems</a>, <em>Transactions of the Association for Computational Linguistics, vol. 8, 2020</em></p>
